# -*- coding: utf-8 -*-
"""Copy of CodeNameBiffExperimental.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w5BZJTu7N4E_WifMSxwkul7NvgAesy5d

##Starters

###Call in Data
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn import neighbors
from sklearn import naive_bayes

import pandas as pd
MLBStats2021 = pd.read_csv("2021MLBStats.csv")
MLBStats2020 = pd.read_csv("2020MLBStats.csv")
MLBStats2019 = pd.read_csv("2019MLBStats.csv")
MLBStats2018 = pd.read_csv("2018MLBStats.csv")
MLBStats2017 = pd.read_csv("2017MLBStats.csv")

from google.colab import drive
drive.mount('/content/drive')

MLBStats2021

df21 = pd.DataFrame(MLBStats2021)
df20 = pd.DataFrame(MLBStats2020)
df19 = pd.DataFrame(MLBStats2019)
df18 = pd.DataFrame(MLBStats2018)
df17 = pd.DataFrame(MLBStats2017)
  
# Remove column name 'A'
#MLBTeams.drop(['Pos'], axis = 1,inplace=True)
#df20.drop(['G','R','RBI','SO','AVG','SLG','OPS'], axis = 1,inplace=True)
##df19.drop(['G','R','RBI','SO','AVG','SLG','OPS'], axis = 1,inplace=True)
#df18.drop(['G','R','RBI','SO','AVG','SLG','OPS'], axis = 1,inplace=True)
#df17.drop(['G','R','RBI','SO','AVG','SLG','OPS'], axis = 1,inplace=True)

df21.sort_values(by=['Team'], inplace=True)
df20.sort_values(by=['Team'], inplace=True)
df19.sort_values(by=['Team'], inplace=True)
df18.sort_values(by=['Team'], inplace=True)
df17.sort_values(by=['Team'], inplace=True)

df21

df19

#dfv1.to_csv('2020MLBTable1.csv', index = False)
#dfv2.to_csv('2019MLBTable1.csv', index = False)
#dfv3.to_csv('2018MLBTable1.csv', index = False)
#dfv4.to_csv('2017MLBTable1.csv', index = False)

ya = pd.merge(df21,df19,how='outer')

ya2= pd.merge(ya,df18,how='outer')

MLBTeams = pd.merge(ya2,df17,how='outer')

MLBTeams.drop(['Pos'], axis = 1,inplace=True)

MLBTeams

#labels, teams = pd.factorize(MLBTeams.Team)
#MLBTeams['Team'] = labels

MLBTeams

MLBTeams

MLB = MLBTeams.to_numpy()

MLB

#MLBTeams.sort_values(by=['Team'], inplace=True)

#df21num

data = pd.read_csv('merged_pitching.txt')
data.columns = ["NA","Player","Team","Age","G","GS","CG","SHO","IP","H","ER","K","BB","HR","W","L","SV","BS","HLD","ERA","WHIP","Year"]
data.sort_values(by=['Year'],ascending=True,inplace=True)
data

a = 2021
b = 2019
c = 2018
d = 2017
data1 = data[data['Year'] >= a]
datav1 = data[data['Year'] < 2021]

data2 = datav1[datav1['Year'] >= b]
datav2 = datav1[datav1['Year'] < b]

data3 = datav2[datav2['Year']>=c]
datav3 = datav2[datav2['Year']<c]

data4 = datav3[datav3['Year']>=d]

data1.sort_values(by=['Team'], inplace=True)
data2.sort_values(by=['Team'], inplace=True)
data3.sort_values(by=['Team'], inplace=True)
data4.sort_values(by=['Team'], inplace=True)

yep = pd.merge(data1,data2,how='outer')
yepper = pd.merge(yep,data3,how='outer')
MLBPitching = pd.merge(yepper,data4,how='outer')

MLBs = MLBPitching.drop(['Year','NA'], axis=1)
MLB_pitch = MLBs.to_numpy()
MLBPitching

"""###Baller Level: Experimental"""

def BallerLevel(df1, array, array2):
  for i in range(len(df1)):
    AB = df1[i][3]
    H = df1[i][4]
    TwoB = df1[i][5]
    ThreeB = df1[i][6]
    HR = df1[i][7]
    SB = df1[i][8]
    CS = df1[i][9]
    BB = df1[i][10]
    SH = df1[i][11]
    SF = df1[i][12]
    HBP = df1[i][13]
    OBP = df1[i][14]
    TB = H + TwoB + (2*ThreeB) + (3*HR)
    
    A = (H + BB + HBP - CS)
    B = TB + (.26*(BB - 24 + HBP)) + (.98*(SB + SH + SF))
    C = 1.02*(AB + BB + SF + HBP)
    if C==0:
      C = +1
    Baller = (A*B)/C
    array.append(df1[i][0])
    array2.append(Baller)

  return array, array2

"""###Organization

####Stuff
"""

Average = pd.DataFrame(columns = ['Team','Age','G','AB','R','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS'])

#dfavg.to_numpy()

dfavg = np.zeros(120*20)
dfavg = dfavg.reshape(120,20)

dfavg.shape

dfavg

Team = MLB[1][1]
count = 0
index = 0
dfavg = np.zeros(120*20)
dfavg = dfavg.reshape(120,20)
for i in range(len(MLB)):
  Team = MLB[i][1]
  for j in range(2,22):
    dfavg[index][j-2] = (dfavg[index][j-2]) + (MLB[i][j])
  count = count + 1
  if i != 2791:
    next = MLB[i+1][1]
  else:
    for j in range(0,20):
      dfavg[index][j] = (dfavg[index][j]) / count
  if(Team != next):
    for j in range(0,20):
      dfavg[index][j] = (dfavg[index][j]) / count
    count = 0
    index = index + 1

dfpitch = np.zeros(120*18)
dfpitch = dfpitch.reshape(120,18)
count = 0
index = 0

for i in range(len(MLB_pitch)):
  Team = MLB_pitch[i][1]
  for j in range(2,20):
    dfpitch[index][j-2] = (dfpitch[index][j-2]) + (MLB_pitch[i][j])
  count = count + 1
  if i != 3493:
    next = MLB_pitch[i+1][1]
  else:
    for j in range(0,18):
      dfpitch[index][j] = (dfpitch[index][j]) / count
  if(Team != next):
    for j in range(0,18):
      dfpitch[index][j] = (dfpitch[index][j]) / count
    count = 0
    index = index + 1

Averagepitch = np.array(dfpitch)

Averagepitch[0,16]

dfpitch[:,0]

dfavg[:,0]

dfavg[:,0]

Averagenum = np.array(dfavg)

Averagenum

Features = np.delete(Averagenum,3,axis=1)

Features.shape

DFeatures = pd.DataFrame(Features, columns = ['Age','G','AB','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS'])

DFeatures

DFAverage = pd.DataFrame(Averagenum, columns = ['Age','G','AB','R','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS'])

DFAverage

winnrate = [.321,.559,.321,.567,.438,.566,.512,.494,.460,.475,.584,.457,.475,.644,.414,.578,.451,.475,.564,.531,.506,.377,.488,.556,.653,.552,.608,.370,.562,.401,
            .525,.593,.333,.519,.519,.447,.463,.574,.438,.292,.650,.364,.444,.647,.352,.546,.612,.531,.632,.595,.500,.426,.432,.420,.475,.550,.589,.482,.414,.587,
            .506,.548,.290,.676,.579,.383,.414,.552,.551,.395,.629,.358,.494,.559,.391,.590,.480,.475,.641,.595,.494,.509,.407,.549,.451,.453,.556,.414,.451,.506,
            .566,.444,.463,.566,.558,.414,.420,.623,.534,.395,.622,.494,.494,.644,.475,.531,.522,.432,.560,.463,.407,.463,.438,.482,.395,.512,.494,.482,.469,.493]

winnrate

Winnrate = np.array(winnrate)

Winnrate.shape

DFAverage.shape

"""####All That Noise"""

Team = MLB[1][1]
count = 0
index = 0
AVGame = np.zeros(120*20)
AVGame = AVGame.reshape(120,20)
for i in range(len(MLB)):
  Team = MLB[i][1]
  for j in range(2,22):
    AVGame[index][j-2] = (AVGame[index][j-2]) + (MLB[i][j])
  count = count + 1
  if i != 2791:
    next = MLB[i+1][1]
  else:
    for h in range(0,16):
      AVGame[index][h] = (AVGame[index][h]) / 162
    for j in range(16,20):
      AVGame[index][j] = (AVGame[index][j]) / count
  if(Team != next):
    for h in range(0,16):
      AVGame[index][h] = (AVGame[index][h]) / 162
    for j in range(16,20):
      AVGame[index][j] = (AVGame[index][j]) / count
    count = 0
    index = index + 1

AVGame

Averagegame = np.array(AVGame)

Whatever = pd.DataFrame(Averagegame, columns = ['Age','G','AB','R','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS'])

Averagegame[:,3]

Whatever

Features2 = np.delete(Averagegame,3,axis=1)

DFeatures2 = pd.DataFrame(Features2, columns = ['Age','G','AB','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS'])

Averagepitch.shape

Pitchers = np.delete(Averagepitch,17,axis=1)

"""###Classification

####Classifying
"""

from sklearn import linear_model
reg = linear_model.LinearRegression()

train_data = Averagegame[0:90]

test_data = Averagegame[90:120]

train_target = winnrate[0:90]

test_target = winnrate[90:120]

train_data=train_data.astype('float')

train_target

#reg.fit(train_data,train_target)
reg.fit(Pitchers,Averagepitch[:,17])

#print(reg.score(train_data,train_target))
#print(reg.score(test_data,test_target))
#print(reg.score(Averagegame,winnrate))

reg.score(Pitchers,Averagepitch[:,17])

Averagepitch[:,17]

reg.predict(Pitchers)

#plt.plot(Averagegame[:,3],reg.predict(Features2),'ko')

#plt.plot(Averagepitch[:,17],reg.predict(Pitchers),'ko')

#plt.plot(reg.coef_,)

#reg.coef_

#reg.score(test_data,test_target)

"""####More Classifying"""

from sklearn import linear_model
reg1 = linear_model.BayesianRidge(alpha_1=1e-06)
reg1.fit(train_data,train_target)
print(reg1.score(train_data,train_target))
print(reg1.score(test_data,test_target))
print(reg1.score(Averagegame,winnrate))

las = linear_model.LassoLars(alpha=.01,normalize=False)
las.fit(train_data,train_target)
print(las.score(train_data,train_target))
print(las.score(test_data,test_target))
print(las.score(Averagegame,winnrate))

SGD = linear_model.SGDRegressor()
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
SGD = make_pipeline(StandardScaler(),linear_model.SGDRegressor(max_iter=1000, tol=1e-3))
SGD.fit(train_data,train_target)
print(SGD.score(train_data,train_target))
print(SGD.score(test_data,test_target))
print(SGD.score(Averagegame,winnrate))

"""####MLPRegressor"""

from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split

MLPRegressor(hidden_layer_sizes=(2))

regr = MLPRegressor(random_state=1).fit(train_data,train_target)

regr.predict(train_data)

regr.score(test_data,test_target)

regr.coefs_

"""####XGBoost

"""

!pip install 'neptune-contrib[monitoring]>=0.24.9'

import neptune
import xgboost as xgb
from neptunecontrib.monitoring.xgboost_monitor import neptune_callback

neptune.init('shared/XGBoost-integration',
             api_token='ANONYMOUS')

X, y = Averagegame,winnrate
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102030)

dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

params = {'max_depth': 5,
          'eta': 0.5,
          'gamma': 0.1,
          'silent': 1,
          'subsample': 1,
          'lambda': 1,
          'alpha': 0.35,
          'objective': 'reg:linear',
          'eval_metric': ['mae', 'rmse']}
watchlist = [(dtest, 'eval'), (dtrain, 'train')]
num_round = 20

neptune.create_experiment(name='xgb', tags=['sklearn'], params=params)
XGBreg = xgb.XGBRegressor(**params)
XGBreg.fit(X_train, y_train,
        eval_metric=['mae', 'rmse'],
        eval_set=[(X_test, y_test)],
        callbacks=[neptune_callback(log_tree=[0,1])])

XGBreg.score(Averagegame,winnrate)

XGBreg.predict(Averagegame)

plt.plot(winnrate,XGBreg.predict(Averagegame),'ko')

"""### Experimental"""

ERAs = []
index = 0
for i in MLB_pitch:
  ERAs.append(MLB_pitch[index,18])
  index = index+1
ERAs

ERAS = np.array(ERAs)

ERAS = ERAS.flatten()

q75,q25 = np.percentile(ERAS,[75,25])

print(q75)
print(q25)

ERAS

intr_qr = q75-q25
 
max = q75+(1.5*intr_qr)
min = q25-(1.5*intr_qr)


ERAS = ERAS[ERAS < max]
ERAS = ERAS[ERAS > min]

ERAS

ERAS[1]

Gera = 0
for i in range(len(ERAS)):
  Gera = Gera + ERAS[i]

Gera = Gera/(len(ERAS))

Gera

"""##Nitty Gritty

###Pitfall (007)
"""

A = Averagegame[0][3]
A1 = Averagepitch[0][16]

B = Averagegame[8][3]
B1 = Averagepitch[8][16]

print(A,B)
print(A1,B1)
print(winnrate[24],winnrate[8])

Ascore = A*(winnrate[0]) - (Gera - B1)
Bscore = B*(winnrate[8]) - (Gera - A1)

print(Ascore)
print(Bscore)
print(abs((Ascore-Bscore)/(Ascore+Bscore)))